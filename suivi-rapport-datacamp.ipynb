{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semaine 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration des données:\n",
    "- Analyse des dataframes train_identity, train_transaction, test_identity et test_transaction\n",
    "- Jointure des dataframes\n",
    "- Compréhension des données: Il s'agit de savoir ce que chaque colonne répresente, s'il s'agit d'une variable numérique ou catégorielle.\n",
    "- Le traitement des valeurs manquantes dans les dataframe: Nous réflichissons sur comment traiter les NaN de chaque variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semaine 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite exploration des données:\n",
    "- suppression des variables contenant plus de 80% de NAN\n",
    "- visualisation des données à l'aide de graphiques: On a remarqué que la plupart des transactions sont non frauduleuses. Si on utilise cette base de données comme base pour nos modèles prédictifs et nos analyses, nous pourrions obtenir beaucoup d'erreurs et nos algorithmes seront probablement trop adaptés car ils \"supposeront\" que la plupart des transactions ne sont pas de la fraude. Mais on ne veut pas que notre modèle suppose, nous voulons que notre modèle détecte les modèles qui donnent des signes de fraude!\n",
    "- test de student, comparaison du montant de transaction \"amt\" moyen pour les transaction frauduleuses et non frauduleuses, On a trouvé une p-value largement inférieure au seuil(5%), on rejette alors notre test, donc le montant de transaction \"amt\" moyen pour les transactions frauduleuses est significativement différents du montant de transaction moyen pour les transaction non frauduleuses \n",
    "- Tracer de la variable \"TransacrionDT\" pour l'échantillon train et test. On a remarqué que les dates de transactions de train et de test ne se chevauchent pas, il serait donc prudent d'utiliser la répartition temporelle pour la validation\n",
    "- Apprendre à utiliser github \n",
    "- Implémentation de l'algorithme Random Forest sur un nombre resteint de données: accuracy= 0,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour la semaine prochaine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gérer les strings (auxence)\n",
    "- regarder les correlations entre les variables (anthony)\n",
    "- faire des modèles simples sur un petit nombre de variables, par exemple Naive Bayes, LDA (amina)\n",
    "- commencer à rédiger le rapport (yamina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
