{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La détection des fraudes en ligne est l'une des problématiques les plus courantes et sensibles dans de nombreux secteurs, en particulier les banques. Au cours des dernières années, les tentatives de fraude ont connu une forte hausse, ce qui rend la lutte contre ce phénomène très importante. \n",
    "\n",
    "Cette compétition est un problème de classification binaire - c'est-à-dire que notre variable cible est un attribut binaire (l'utilisateur fait-il le clic frauduleux ou non?) Et notre objectif est de classer les utilisateurs en \"frauduleux\" ou \"non frauduleux\" le mieux possible.\n",
    "\n",
    "On cherche à prédire la probabilité qu'une transaction en ligne soit frauduleuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     \n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns          #version améliorée de matplotlib\n",
    "import pickle as pkl\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set() #pour avoir de plus beau plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par vérifier les données submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud\n",
       "0        3663549      0.5\n",
       "1        3663550      0.5\n",
       "2        3663551      0.5\n",
       "3        3663552      0.5\n",
       "4        3663553      0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub = pd.read_csv('sample_submission.csv')\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge maintenant, les données trains et tests. Les données sont divisées en deux fichiers d'identité et de transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('train_identity.csv')\n",
    "train_trans = pd.read_csv('train_transaction.csv')\n",
    "test_id = pd.read_csv('test_identity.csv')\n",
    "test_trans = pd.read_csv('test_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rassemble les données train et test via la variable TransactionID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_trans, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_trans, test_id, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_id, train_trans, test_id, test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Réduction de mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, on visualise les données à l'aide de graphiques et de tests statistiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Données \"object\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(train.select_dtypes(include=['object']).columns)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Variables discrètes :\n",
    "\n",
    " - ProductCD\n",
    " - emaildomain\n",
    " - card1 - card6\n",
    " - addr1, addr2\n",
    " - P_emaildomain\n",
    " - R_emaildomain\n",
    " - M1 - M9\n",
    " - DeviceType\n",
    " - DeviceInfo\n",
    " - id_12 - id_38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reste des variables sont numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target : isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('isFraud') \\\n",
    "    .count()['TransactionID'] \\\n",
    "    .plot(kind='barh',\n",
    "          title='Distribution of Target in Train',\n",
    "          figsize=(15, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir clairement que la plupart des transactions sont non frauduleuses. Si on utilise cette base de données comme base pour nos modèles prédictifs et nos analyses, nous pourrions obtenir beaucoup d'erreurs et nos algorithmes seront probablement trop adaptés car ils \"supposeront\" que la plupart des transactions ne sont pas de la fraude. Mais on ne veut pas que notre modèle suppose, nous voulons que notre modèle détecte les modèles qui donnent des signes de fraude!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Amt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette variable décrit le montant de la transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "color_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\n",
    "train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Fraud',\n",
    "          color=color_pal[1],\n",
    "          xlim=(-3, 10),\n",
    "         ax= ax1)\n",
    "train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Not Fraud',\n",
    "          color=color_pal[2],\n",
    "          xlim=(-3, 10),\n",
    "         ax=ax2)\n",
    "train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Fraud',\n",
    "          color=color_pal[1],\n",
    "         ax= ax3)\n",
    "train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Not Fraud',\n",
    "          color=color_pal[2],\n",
    "         ax=ax4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean transaction amt for fraud is {:.4f}'.format(train.loc[train['isFraud'] == 1]['TransactionAmt'].mean()))\n",
    "print('Mean transaction amt for non-fraud is {:.4f}'.format(train.loc[train['isFraud'] == 0]['TransactionAmt'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print(stats.ttest_ind(train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'] ,train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'] ,equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant un test de student on remarque qu'il y a une différence significative entre les deux moyennes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProductCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le produit pour chaque transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('ProductCD') \\\n",
    "    ['TransactionID'].count() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Count of Observations by ProductCD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('ProductCD')['isFraud'] \\\n",
    "    .mean() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Percentage of Fraud by ProductCD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que :\n",
    " - W a le plus grand nombre d'observations, C a le moins.\n",
    " - C a le plus grand pourcentage de fraude >11%\n",
    " - W a le moins avec ~2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## card1 - card6\n",
    "\n",
    "Informations sur les cartes de paiement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_cols = [c for c in train.columns if 'card' in c]\n",
    "train[card_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = 0\n",
    "for c in card_cols:\n",
    "    if train[c].dtype in ['float64','int64']:\n",
    "        train[c].plot(kind='hist',\n",
    "                                      title=c,\n",
    "                                      bins=50,\n",
    "                                      figsize=(15, 2),\n",
    "                                      color=color_pal[color_idx])\n",
    "    color_idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fr = train.loc[train['isFraud'] == 1]\n",
    "train_nofr = train.loc[train['isFraud'] == 0]\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_fr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax1, title='Count of card4 fraud')\n",
    "train_nofr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax2, title='Count of card4 non-fraud')\n",
    "train_fr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\n",
    "train_nofr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeviceType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('DeviceType') \\\n",
    "    .mean()['isFraud'] \\\n",
    "    .sort_values() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 5),\n",
    "          title='Percentage of Fraud by Device Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeviceInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('DeviceInfo') \\\n",
    "    .count()['TransactionID'] \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .head(20) \\\n",
    "    .plot(kind='barh', figsize=(15, 5), title='Top 20 Devices in Train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['TransactionDT'], label='train');\n",
    "plt.hist(test['TransactionDT'], label='test');\n",
    "plt.legend();\n",
    "plt.title('Transaction dates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus, on voit que les dates des données Train et Test ont une intersection vide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nettoyage des NaN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = train.isnull().sum()\n",
    "print (missing_values_count[0:10])\n",
    "total_cells = np.product(train.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "print (\"% of missing data = \",(total_missing/total_cells) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que 45% des données du train sont des valeurs manquantes, nettoyons tout ça !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_many_null_attr(data):\n",
    "    many_null_cols = [col for col in data.columns if data[col].isnull().sum() / data.shape[0] > 0.9]\n",
    "    return many_null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_null = get_too_many_null_attr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_many_repeated_val(data):\n",
    "    big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "    return big_top_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_too_many_repeated_val(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_03'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que 88% des données sont des NaN, et 10% sont des valeurs nulles. Soit 98% des données sont des valeurs manquantes, donc inutiles !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les chaînes de caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot incoding  et label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pourvoir utiliser les variables contenant des chaînes de caractères, on utilise la méthode de one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(col,col_name):    \n",
    "    data = np.array(col.fillna(col.mode()[0]))\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(data)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    name = [col_name+str(i) for i in range(onehot_encoded.shape[1])]\n",
    "    onehot_encoded = pd.DataFrame(onehot_encoded,columns=name)\n",
    "    return (onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_non_num = train[train.columns[~train.columns.isin(col_num)]]\n",
    "X_non_num.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card4 = onehot(train[\"card4\"],\"card4\")\n",
    "email = onehot(train[\"P_emaildomain\"],\"P_emaildomain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " email_label= labelencod(train[\"P_emaildomain\"],\"P_emaildomain\")\n",
    " card4_label = labelencod(train[\"card4\"],\"card4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_card_mail = X.join(card4).join(email)\n",
    "X_card_mail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_card_mail_label = X.join(card4_label).join(email_label)\n",
    "X_card_mail_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction de la probabilité du nombre de fraudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[\"isFraud\"] \n",
    "X = X.loc[:, X.columns != \"isFraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split nos données en train(67%) et test(33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temps(second):\n",
    "    m, s = divmod(second, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(\"temps :\",'{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression logistique avec toutes nos varibales numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "log = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "pred_train = log.predict_proba(X_train)\n",
    "print(\"score auc train :\",roc_auc_score(y_train, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "pred = log.predict_proba(X_test)\n",
    "print(\"score auc test :\",roc_auc_score(y_test, pred[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique avec cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation sur toutes nos données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores = cross_val_score(clf, X, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validaiton avec nos données numérique et celles obtenus par le one hot encoding pour les variables \"card4\" et \"P_emaildomain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_card4_email = cross_val_score(clf, X_card_mail, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_card4_email)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater que l'on obtient un auc de 0.7218 qui est le plus élevé obtenu jusqu'à présent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_card4_email_label = cross_val_score(clf, X_card_mail_label, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_card4_email_label)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retranchons nous sur des données moindres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[train[\"isFraud\"]==1])/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seulement 3,49% des données sont des fraudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.0349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000-2094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "train_sample0 = train[train[\"isFraud\"]==0].sample(n=57906)\n",
    "train_sample1 = train[train[\"isFraud\"]==1].sample(n=2094)\n",
    "train_sample = train_sample0.append(train_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = train_sample[col_num]\n",
    "Y_sample = train_sample[\"isFraud\"] \n",
    "X_sample = X_sample.loc[:, X_sample.columns != \"isFraud\"]\n",
    "X_sample = X_sample.fillna(X_sample.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_sample = cross_val_score(clf, X_sample, Y_sample, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sample)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sample = cross_val_score(clf, X_sample, Y_sample, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sample)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les auc obtenu avec une penalty l1 sont bien meilleurs que ceux obtenus prédédement. Toutefois, nous travaillons que sur 60000 données. Le temps de d'exécution est en revanche bien plus grand avec cette méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000*0.0349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000-698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "train_sub0 = train[train[\"isFraud\"]==0].sample(n=19302)\n",
    "train_sub1 = train[train[\"isFraud\"]==1].sample(n=698)\n",
    "train_sub = train_sub0.append(train_sub1)\n",
    "X_sub = train_sub[col_num]\n",
    "Y_sub = train_sub[\"isFraud\"] \n",
    "X_sub = X_sub.loc[:, X_sub.columns != \"isFraud\"]\n",
    "X_sub = X_sub.fillna(X_sub.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_sub = cross_val_score(clf, X_sub, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub = cross_val_score(clf, X_sub, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajouter C = 1/alpha et tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_non_num = X_non_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe = X_sub.reset_index(drop=True)\n",
    "for i in col_non_num:\n",
    "    X_sub_ohe = X_sub_ohe.join(onehot(train_sub[i],i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_sub_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'avec le one hot encoding le temps de calcul est moindre qu'avec le label encoding. De plus, les performence au niveau de l'auc sont meilleures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation pour le paramètre Inverse of regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe = X_sub.reset_index(drop=True)\n",
    "for i in col_non_num:\n",
    "    X_sub_ohe = X_sub_ohe.join(onehot(train_sub[i],i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données centrées réduites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_sub_sc = scaler.fit_transform(X_sub_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_train_sc, X_sub_test_sc, y_sub_train_sc, y_sub_test_sc = train_test_split(X_sub_sc, Y_sub, test_size=0.33, \n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.1,1.1,0.1)\n",
    "for i in t:\n",
    "    if(i%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train_sc, \n",
    "                                                                                           y_sub_train_sc)\n",
    "    pred_train = log.predict_proba(X_sub_test_sc)\n",
    "    pred.append(roc_auc_score(y_sub_test_sc, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.01,0.11,0.01)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train_sc, \n",
    "                                                                                           y_sub_train_sc)\n",
    "    pred_train = log.predict_proba(X_sub_test_sc)\n",
    "    pred.append(roc_auc_score(y_sub_test_sc, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.03, penalty = 'l1', random_state=0)\n",
    "scores_sub_sc = cross_val_score(clf, X_sub_sc, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_sc)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données non centrées réduites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, Y_sub, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.1,1.1,0.1)\n",
    "for i in t:\n",
    "    if(i%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train, y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.01,0.11,0.01)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train, \n",
    "                                                                                           y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=1/11, random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0,1.1,0.1)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='saga', penalty = 'elasticnet', random_state=0, l1_ratio=i).fit(X_sub_train, y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essayer de melanger les données (toutes les données non fraude sont en haut et fraude en bas du DataFrame)\n",
    "essayer avec : df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle = X_sub_ohe.join(Y_sub.reset_index(drop=True))\n",
    "X_shuffle = X_shuffle.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sh = X_shuffle[\"isFraud\"]\n",
    "X_sh = X_shuffle.loc[:, X_shuffle.columns != \"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sh = cross_val_score(clf, X_sh, Y_sh, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sh)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection de variables avec Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables sélectionner par Lasso pour  $\\lambda$=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=1)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns\n",
    "var_ohe = col_ohe[coef!=0]\n",
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nous pouvons constater que la plupart des coefficients ont été mis à zéros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variables sélectionner par Lasso pour $\\lambda$ =0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ohe = col_ohe[coef!=0]\n",
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir qu'en ce lambda le nombre de coefficient différents de ézéros à augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.04, penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.04, penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables sélectionner par Lasso pour  𝜆 =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=0.01)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns\n",
    "var_ohe = col_ohe[coef!=0]\n",
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater que le nombre de coefficients différents de zéros a encore augmenté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
