{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La d√©tection des fraudes en ligne est l'une des probl√©matiques les plus courantes et sensibles dans de nombreux secteurs, en particulier les banques. Au cours des derni√®res ann√©es, les tentatives de fraude ont connu une forte hausse, ce qui rend la lutte contre ce ph√©nom√®ne tr√®s importante. \n",
    "\n",
    "Cette comp√©tition est un probl√®me de classification binaire - c'est-√†-dire que notre variable cible est un attribut binaire (l'utilisateur fait-il le clic frauduleux ou non?) Et notre objectif est de classer les utilisateurs en \"frauduleux\" ou \"non frauduleux\" le mieux possible.\n",
    "\n",
    "On cherche √† pr√©dire la probabilit√© qu'une transaction en ligne soit frauduleuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     \n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns          #version am√©lior√©e de matplotlib\n",
    "import pickle as pkl\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set() #pour avoir de plus beau plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commen√ßons par v√©rifier les donn√©es submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud\n",
       "0        3663549      0.5\n",
       "1        3663550      0.5\n",
       "2        3663551      0.5\n",
       "3        3663552      0.5\n",
       "4        3663553      0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub = pd.read_csv('sample_submission.csv')\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge maintenant, les donn√©es trains et tests. Les donn√©es sont divis√©es en deux fichiers d'identit√© et de transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('train_identity.csv')\n",
    "train_trans = pd.read_csv('train_transaction.csv')\n",
    "test_id = pd.read_csv('test_identity.csv')\n",
    "test_trans = pd.read_csv('test_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rassemble les donn√©es train et test via la variable TransactionID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train_trans, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_trans, test_id, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_id, train_trans, test_id, test_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - R√©duction de m√©moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, on visualise les donn√©es √† l'aide de graphiques et de tests statistiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Donn√©es \"object\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(train.select_dtypes(include=['object']).columns)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Variables discr√®tes :\n",
    "\n",
    " - ProductCD\n",
    " - emaildomain\n",
    " - card1 - card6\n",
    " - addr1, addr2\n",
    " - P_emaildomain\n",
    " - R_emaildomain\n",
    " - M1 - M9\n",
    " - DeviceType\n",
    " - DeviceInfo\n",
    " - id_12 - id_38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reste des variables sont num√©riques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target : isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('isFraud') \\\n",
    "    .count()['TransactionID'] \\\n",
    "    .plot(kind='barh',\n",
    "          title='Distribution of Target in Train',\n",
    "          figsize=(15, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir clairement que la plupart des transactions sont non frauduleuses. Si on utilise cette base de donn√©es comme base pour nos mod√®les pr√©dictifs et nos analyses, nous pourrions obtenir beaucoup d'erreurs et nos algorithmes seront probablement trop adapt√©s car ils \"supposeront\" que la plupart des transactions ne sont pas de la fraude. Mais on ne veut pas que notre mod√®le suppose, nous voulons que notre mod√®le d√©tecte les mod√®les qui donnent des signes de fraude!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Amt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette variable d√©crit le montant de la transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "color_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\n",
    "train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Fraud',\n",
    "          color=color_pal[1],\n",
    "          xlim=(-3, 10),\n",
    "         ax= ax1)\n",
    "train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Not Fraud',\n",
    "          color=color_pal[2],\n",
    "          xlim=(-3, 10),\n",
    "         ax=ax2)\n",
    "train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Fraud',\n",
    "          color=color_pal[1],\n",
    "         ax= ax3)\n",
    "train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Not Fraud',\n",
    "          color=color_pal[2],\n",
    "         ax=ax4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean transaction amt for fraud is {:.4f}'.format(train.loc[train['isFraud'] == 1]['TransactionAmt'].mean()))\n",
    "print('Mean transaction amt for non-fraud is {:.4f}'.format(train.loc[train['isFraud'] == 0]['TransactionAmt'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print(stats.ttest_ind(train.loc[train['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'] ,train.loc[train['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'] ,equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant un test de student on remarque qu'il y a une diff√©rence significative entre les deux moyennes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProductCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le produit pour chaque transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('ProductCD') \\\n",
    "    ['TransactionID'].count() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Count of Observations by ProductCD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('ProductCD')['isFraud'] \\\n",
    "    .mean() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Percentage of Fraud by ProductCD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que :\n",
    " - W a le plus grand nombre d'observations, C a le moins.\n",
    " - C a le plus grand pourcentage de fraude >11%\n",
    " - W a le moins avec ~2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## card1 - card6\n",
    "\n",
    "Informations sur les cartes de paiement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_cols = [c for c in train.columns if 'card' in c]\n",
    "train[card_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = 0\n",
    "for c in card_cols:\n",
    "    if train[c].dtype in ['float64','int64']:\n",
    "        train[c].plot(kind='hist',\n",
    "                                      title=c,\n",
    "                                      bins=50,\n",
    "                                      figsize=(15, 2),\n",
    "                                      color=color_pal[color_idx])\n",
    "    color_idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fr = train.loc[train['isFraud'] == 1]\n",
    "train_nofr = train.loc[train['isFraud'] == 0]\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_fr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax1, title='Count of card4 fraud')\n",
    "train_nofr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax2, title='Count of card4 non-fraud')\n",
    "train_fr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\n",
    "train_nofr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeviceType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('DeviceType') \\\n",
    "    .mean()['isFraud'] \\\n",
    "    .sort_values() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 5),\n",
    "          title='Percentage of Fraud by Device Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeviceInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('DeviceInfo') \\\n",
    "    .count()['TransactionID'] \\\n",
    "    .sort_values(ascending=False) \\\n",
    "    .head(20) \\\n",
    "    .plot(kind='barh', figsize=(15, 5), title='Top 20 Devices in Train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train['TransactionDT'], label='train');\n",
    "plt.hist(test['TransactionDT'], label='test');\n",
    "plt.legend();\n",
    "plt.title('Transaction dates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus, on voit que les dates des donn√©es Train et Test ont une intersection vide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nettoyage des NaN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = train.isnull().sum()\n",
    "print (missing_values_count[0:10])\n",
    "total_cells = np.product(train.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "print (\"% of missing data = \",(total_missing/total_cells) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que 45% des donn√©es du train sont des valeurs manquantes, nettoyons tout √ßa !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_many_null_attr(data):\n",
    "    many_null_cols = [col for col in data.columns if data[col].isnull().sum() / data.shape[0] > 0.9]\n",
    "    return many_null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_null = get_too_many_null_attr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_too_many_repeated_val(data):\n",
    "    big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "    return big_top_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_too_many_repeated_val(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_03'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que 88% des donn√©es sont des NaN, et 10% sont des valeurs nulles. Soit 98% des donn√©es sont des valeurs manquantes, donc inutiles !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les cha√Ænes de caract√®res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot incoding  et label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pourvoir utiliser les variables contenant des cha√Ænes de caract√®res, on utilise la m√©thode de one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(col,col_name):    \n",
    "    data = np.array(col.fillna(col.mode()[0]))\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(data)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    name = [col_name+str(i) for i in range(onehot_encoded.shape[1])]\n",
    "    onehot_encoded = pd.DataFrame(onehot_encoded,columns=name)\n",
    "    return (onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_non_num = train[train.columns[~train.columns.isin(col_num)]]\n",
    "X_non_num.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card4 = onehot(train[\"card4\"],\"card4\")\n",
    "email = onehot(train[\"P_emaildomain\"],\"P_emaildomain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " email_label= labelencod(train[\"P_emaildomain\"],\"P_emaildomain\")\n",
    " card4_label = labelencod(train[\"card4\"],\"card4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_card_mail = X.join(card4).join(email)\n",
    "X_card_mail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_card_mail_label = X.join(card4_label).join(email_label)\n",
    "X_card_mail_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©diction de la probabilit√© du nombre de fraudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©gression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[\"isFraud\"] \n",
    "X = X.loc[:, X.columns != \"isFraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split nos donn√©es en train(67%) et test(33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temps(second):\n",
    "    m, s = divmod(second, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(\"temps :\",'{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression logistique avec toutes nos varibales num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "log = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "pred_train = log.predict_proba(X_train)\n",
    "print(\"score auc train :\",roc_auc_score(y_train, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "pred = log.predict_proba(X_test)\n",
    "print(\"score auc test :\",roc_auc_score(y_test, pred[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique avec cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation sur toutes nos donn√©es num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores = cross_val_score(clf, X, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validaiton avec nos donn√©es num√©rique et celles obtenus par le one hot encoding pour les variables \"card4\" et \"P_emaildomain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_card4_email = cross_val_score(clf, X_card_mail, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_card4_email)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater que l'on obtient un auc de 0.7218 qui est le plus √©lev√© obtenu jusqu'√† pr√©sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_card4_email_label = cross_val_score(clf, X_card_mail_label, Y, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_card4_email_label)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retranchons nous sur des donn√©es moindres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[train[\"isFraud\"]==1])/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seulement 3,49% des donn√©es sont des fraudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000*0.0349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60000-2094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "train_sample0 = train[train[\"isFraud\"]==0].sample(n=57906)\n",
    "train_sample1 = train[train[\"isFraud\"]==1].sample(n=2094)\n",
    "train_sample = train_sample0.append(train_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = train_sample[col_num]\n",
    "Y_sample = train_sample[\"isFraud\"] \n",
    "X_sample = X_sample.loc[:, X_sample.columns != \"isFraud\"]\n",
    "X_sample = X_sample.fillna(X_sample.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_sample = cross_val_score(clf, X_sample, Y_sample, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sample)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sample = cross_val_score(clf, X_sample, Y_sample, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sample)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les auc obtenu avec une penalty l1 sont bien meilleurs que ceux obtenus pr√©d√©dement. Toutefois, nous travaillons que sur 60000 donn√©es. Le temps de d'ex√©cution est en revanche bien plus grand avec cette m√©thodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000*0.0349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000-698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "train_sub0 = train[train[\"isFraud\"]==0].sample(n=19302)\n",
    "train_sub1 = train[train[\"isFraud\"]==1].sample(n=698)\n",
    "train_sub = train_sub0.append(train_sub1)\n",
    "X_sub = train_sub[col_num]\n",
    "Y_sub = train_sub[\"isFraud\"] \n",
    "X_sub = X_sub.loc[:, X_sub.columns != \"isFraud\"]\n",
    "X_sub = X_sub.fillna(X_sub.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scores_sub = cross_val_score(clf, X_sub, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub = cross_val_score(clf, X_sub, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajouter C = 1/alpha et tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_non_num = X_non_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe = X_sub.reset_index(drop=True)\n",
    "for i in col_non_num:\n",
    "    X_sub_ohe = X_sub_ohe.join(onehot(train_sub[i],i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_sub_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'avec le one hot encoding le temps de calcul est moindre qu'avec le label encoding. De plus, les performence au niveau de l'auc sont meilleures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation pour le param√®tre Inverse of regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_ohe = X_sub.reset_index(drop=True)\n",
    "for i in col_non_num:\n",
    "    X_sub_ohe = X_sub_ohe.join(onehot(train_sub[i],i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donn√©es centr√©es r√©duites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_sub_sc = scaler.fit_transform(X_sub_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_train_sc, X_sub_test_sc, y_sub_train_sc, y_sub_test_sc = train_test_split(X_sub_sc, Y_sub, test_size=0.33, \n",
    "                                                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.1,1.1,0.1)\n",
    "for i in t:\n",
    "    if(i%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train_sc, \n",
    "                                                                                           y_sub_train_sc)\n",
    "    pred_train = log.predict_proba(X_sub_test_sc)\n",
    "    pred.append(roc_auc_score(y_sub_test_sc, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.01,0.11,0.01)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train_sc, \n",
    "                                                                                           y_sub_train_sc)\n",
    "    pred_train = log.predict_proba(X_sub_test_sc)\n",
    "    pred.append(roc_auc_score(y_sub_test_sc, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.03, penalty = 'l1', random_state=0)\n",
    "scores_sub_sc = cross_val_score(clf, X_sub_sc, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_sc)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donn√©es non centr√©es r√©duites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, Y_sub, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.1,1.1,0.1)\n",
    "for i in t:\n",
    "    if(i%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train, y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0.01,0.11,0.01)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='liblinear', penalty = 'l1', C=i, random_state=0).fit(X_sub_train, \n",
    "                                                                                           y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)\n",
    "\n",
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour C = \",t[np.argmax(pred)], \" ,auc = \",np.max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=1/11, random_state=0)\n",
    "scores_sub_ohe = cross_val_score(clf, X_sub_ohe, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_ohe)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "tstart = time.time()\n",
    "t = np.arange(0,1.1,0.1)\n",
    "for i in t:\n",
    "    if((i*10)%2==0): print(i)\n",
    "    log = LogisticRegression(solver ='saga', penalty = 'elasticnet', random_state=0, l1_ratio=i).fit(X_sub_train, y_sub_train)\n",
    "    pred_train = log.predict_proba(X_sub_test)\n",
    "    pred.append(roc_auc_score(y_sub_test, pred_train[:, 1]))\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essayer de melanger les donn√©es (toutes les donn√©es non fraude sont en haut et fraude en bas du DataFrame)\n",
    "essayer avec : df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffle = X_sub_ohe.join(Y_sub.reset_index(drop=True))\n",
    "X_shuffle = X_shuffle.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sh = X_shuffle[\"isFraud\"]\n",
    "X_sh = X_shuffle.loc[:, X_shuffle.columns != \"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sh = cross_val_score(clf, X_sh, Y_sh, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sh)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection de variables avec Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables s√©lectionner par Lasso pour  $\\lambda$=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=1)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns\n",
    "var_ohe = col_ohe[coef!=0]\n",
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nous pouvons constater que la plupart des coefficients ont √©t√© mis √† z√©ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variables s√©lectionner par Lasso pour $\\lambda$ =0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ohe = col_ohe[coef!=0]\n",
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir qu'en ce lambda le nombre de coefficient diff√©rents de √©z√©ros √† augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.04, penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', C=0.04, penalty = 'l1', random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables s√©lectionner par Lasso pour  ùúÜ =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=0.01)\n",
    "clf.fit(X_sub_ohe,Y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_\n",
    "col_ohe = X_sub_ohe.columns\n",
    "var_ohe = col_ohe[coef!=0]\n",
    "X_lasso = X_sub_ohe[var_ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(var_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater que le nombre de coefficients diff√©rents de z√©ros a encore augment√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=5,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time.time()\n",
    "clf = LogisticRegression(solver ='liblinear', penalty = 'l1', C=0.04, random_state=0)\n",
    "scores_sub_lasso = cross_val_score(clf, X_lasso, Y_sub, cv=10,scoring='roc_auc')\n",
    "print(\"score auc :\",scores_sub_lasso)\n",
    "tend = time.time()\n",
    "temps(tend-tstart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
